# Airflow Executor Configuration
AIRFLOW__CORE__EXECUTOR=CeleryExecutor

# Celery Configuration
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://postgres:postgres@postgres:5432/airflow_kaggle

# Database Connection
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow_kaggle

# Security and Logging
AIRFLOW__CORE__FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
AIRFLOW__CORE__LOGGING_LEVEL=INFO

# Example DAGs
AIRFLOW__CORE__LOAD_EXAMPLES=False

# API Authentication
AIRFLOW__API__AUTH_BACKEND= 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'


# Google Cloud Configuration
GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/.google/fashionimages-441305-8e0ac87a473e.json
AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT= 'google-cloud-platform://?extra__google_cloud_platform__key_path=/opt/airflow/.google/fashionimages-441305-8e0ac87a473e.json'
GCP_PROJECT_ID= 'fashionimages-441305'
GCP_GCS_BUCKET= 'de_data_lake_fashionimages-441305'


# BigQuery Configuration
BIGQUERY_DATASET_1= "${TF_VAR_BQ_DATASET_STAGING:-de_dataset_staging}"
BIGQUERY_DATASET_2= "${TF_VAR_BQ_DATASET_WAREHOUSE:-de_dataset_warehouse}"

# Kaggle Configuration
KAGGLE_CONFIG_DIR= /opt/airflow/.kaggle/

# Default Database Connection
AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql+psycopg2://airflow:airflow@postgres/postgres
